# wget -m

Учебный проект: реализация упрощенной версии "wget -m" - утилиты для мирроринга сайта посредством рекурсивной 
загрузки веб-страниц со всем их содержимым и заменой всех ссылок внутри html (в рамках указанной
глубины рекурсии, домена и robots.txt) на относительные локальные пути.

## Возможности

Программа поддерживает:
- ограничение скачивания согласно robots.txt;
- ограничение скачивания дочерних страниц в соответствии с указанным уровнем рекурсии при запуске программы(флаг -r);
- скачивание ассетов и дочерних страниц без дублирования;
- использование таймаута на скачивание каждой url-ссылки(флаг -timeout).

## Структура проекта

L2.15/
├── cmd/        # Управляющий код утилиты - взаимодействие с пользователем, вызов парсера
├── crawler/    # Основной код краулера
├── fetcher/    # Возвращает содержимое страницы
├── parser/     # Анализирует и возвращает список дочерних страниц и ассетов для скачивания
├── saver/      # Загрузчик файлов
├── mirror/     # Директория для сохранения скачиваемой ссылки
├── go.mod 
├── main.go     # Точка входа в приложение
├── task.md     # Описание изначальной задачи
└── README.md